<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visualization Critique | Zoe-Kylie</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <nav>
            <a href="index.html">Home</a>
            <a href="lab02.html">Lab 2: AI Evaluation</a>
            <a href="lab03.html" class="active">Lab 3: Visualization Critique</a>
            <!-- Add more lab links as the semester progresses -->
        </nav>
        <h1>Visualization Critique</h1>
    </header>

    <main>
        <section>
            <h2>Visualization</h2>
            <figure>
                <img src="images/Major_Large_Language_Models.png" alt="" width="500">
                <figcaption>
                    <strong>Title:</strong> [Major Large Language Models]<br>
                    <strong>Source:</strong> <a href="https://informationisbeautiful.net/visualizations/the-rise-of-generative-ai-large-language-models-llms-like-chatgpt/" target="_blank"> Information is Beautiful</a>
                </figcaption>
            </figure>
        </section>

        <section>
            <h2>Critique</h2>
            
            <h3>Information Resolution</h3>
            <p>When first viewing the graph analyzing major Large Language Models, my partner and I noticed that we felt a bit overwhelmed by what was happening in the graphic. Deciphering the map is not intuitive, but becomes more understandable as you spend time with it. There is clear analysis on how these LLM’s have changed and developed over time. The form in which these LLM’s development is being measured is Massive Multitask Language Understanding (MMLU). Which calculates the LLM’s ability to communicate, reason, and share information. Part of the reason that this graphic seems overwhelming is due to the high volume of information it aims to share. This ties directly with Tufte’s idea of resolution, where his goal is to show as much data as possible, while using clean and effective visuals. The argument here is that the human mind is able to intake large amounts of data, when it is presented in a straight and direct manner.
Although this graph is showing a growth in MMLU, it is only answering the question of what is happening, and gives no context as to why or how this growth is happening. The reason we are unable to answer these questions is due to the minimal qualitative data presented. Later, we are able to see more qualitative data we can join with the first chart, but even then we run into issues of trying to prove causation. 
</p>

            <h3>Effects Without Causes </h3>
            <p>After critiquing the visualization part of the data, the two of Tufte’s concerns that we noticed in this data visualization were effects without causes and overreaching. For the effects without causes, we noticed that the visualizations showed strong data and results, however, we noticed that it does not go into detail about how some of the data was collected. One example is the visualization below, “What are people using ChatGPT for?” Looking at it, the effect is visually persuasive, but the lack of explanation lowers the overall clarity, and it does not show us where the data has been collected from, where was it collected from, or by whom it was surveyed.  I like how in the first visualization, the line plot, each circle or diamond has an in depth articles of information with sources, but comparing some of the other visualizations, we could not get more information on it. Because of that, some of the questions we raised were how representative these percentages were.</p>
            <h3>Overreaching</h3>
            <p>The other Tufte’s concern was overreaching, we noticed that one of the visualizations, “OpenAI, creators of ChatGPT, stole the LLM show,” showed that OpenAI models that performed well, however, it did not account for future uncertainty, alternative metrics, or limitations of the benchmarks themselves. One unanswered question we had was how the visualization is excellent at summarizing trends, but why it is less effective at encouraging critical evaluation of the data.</p>
<img src="images/ChatGPT_Uses.png" width="400">
            <h3>Conclusion</h3>
            <p> As we worked through analyzing this graph, we realized that at first glance this shows information that could easily be misconstrued to show causation. However,this graph does a good job of showing a large data set, and later expands on each LLM's progression through additional visuals, and articles.  </p>
        </section>
    </main>

    <footer>
        <p>© 2026 Zoe-Kylie Sanchez</p>
    </footer>
</body>
</html>